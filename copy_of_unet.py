# -*- coding: utf-8 -*-
"""Copy of Unet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vlsf_NqRNuCID2spkGt8GeZJbSGkhKbF
"""

import tensorflow as tf
from tensorflow import keras

from google.colab import drive
drive.mount('/content/drive')

import os
import keras
import numpy as np
import pandas as pd
import cv2
import tensorflow
from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, ZeroPadding2D
from sklearn.preprocessing import LabelEncoder , OneHotEncoder
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

dataset_path = os.listdir('/content/drive/MyDrive/Dataset3')
emotion_types = os.listdir('/content/drive/MyDrive/Dataset3')
print (emotion_types)  #what kinds of emotions are in this dataset

print("Types of emotions found: ", len(dataset_path))

emotions = []

for item in emotion_types:
 # Get all the file names
 all_emotions = os.listdir('/content/drive/MyDrive/Dataset3' + '/' +item)
 #print(all_emotion)

 # Add them to the list
 for emotion in all_emotions:
    emotions.append((item, str('emotions_dataset' + '/' +item) + '/' + emotion))
    print(emotions)

# Build a dataframe        
emotions_df = pd.DataFrame(data=emotions, columns=['game no.', 'image'])
print(emotions_df.head())
print(emotions_df.tail())

# Let's check how many samples for each category are present
print("Total number of emotions in the dataset: ", len(emotions_df))

emotion_count = emotions_df['game no.'].value_counts()

print("emotions in each category: ")
print(emotion_count)

path = '/content/drive/MyDrive/Dataset3'

im_size = 572
images = []
labels = []

for i in emotion_types:
    data_path = path + '/'+str(i)  
    filenames = [i for i in os.listdir(data_path) ]
   
    for f in filenames:
        img = cv2.imread(data_path + '/' + f)
        img = cv2.resize(img, (im_size, im_size))
        images.append(img)
        labels.append(i)

images = np.array(images)
images = images.astype('float16') / 255.0
images.shape

y = emotions_df['game no.'].values
print(y[:5], y[-10 : ])

y_labelencoder = LabelEncoder ()
y = y_labelencoder.fit_transform (y)
# y = to_categorical(y, 2)
# # print (y.shape)
y[:5], y[-10 : ]

images, y = shuffle(images,y, random_state=1)

train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.20, random_state=415)

#inpect the shape of the training and testing.
print(train_x.shape)
print(train_y.shape)
print(test_x.shape)
print(test_y.shape)



class UNet(keras.Model):
  def __init__(self):
    super(UNet, self).__init__()

    self.conv_1 = keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu')
    self.conv_2 = keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu')
    self.crop_4 = keras.layers.Cropping2D(((88, 88), (88, 88)))
    self.max_pool_1 = keras.layers.MaxPool2D(pool_size = 2)
    
    self.conv_3 = keras.layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu')
    self.conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu')
    self.crop_3 = keras.layers.Cropping2D(((40, 40), (40, 40)))
    self.max_pool_2 = keras.layers.MaxPool2D(pool_size = 2)

    self.conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, activation = 'relu')
    self.conv_6 = keras.layers.Conv2D(filters = 256, kernel_size = 3, activation = 'relu')
    self.crop_2 = keras.layers.Cropping2D(((16, 16), (16, 16)))
    self.max_pool_3 = keras.layers.MaxPool2D(pool_size = 2)

    self.conv_7 = keras.layers.Conv2D(filters = 512, kernel_size = 3, activation = 'relu')
    self.conv_8 = keras.layers.Conv2D(filters = 512, kernel_size = 3, activation = 'relu')
    self.crop_1 = keras.layers.Cropping2D(((4, 4), (4, 4)))
    self.max_pool_4 = keras.layers.MaxPool2D(pool_size = 2)

    self.conv_9 = keras.layers.Conv2D(filters = 1024, kernel_size = 3, activation = 'relu')
    self.conv_10 = keras.layers.Conv2D(filters = 1024, kernel_size = 3, activation = 'relu')

    self.conv_transpose_1 = keras.layers.Conv2DTranspose(filters = 512, kernel_size = 2, strides = 2, padding = 'same')

    self.conv_11 = keras.layers.Conv2D(filters = 512, kernel_size = 3, activation = 'relu')
    self.conv_12 = keras.layers.Conv2D(filters = 512, kernel_size = 3, activation = 'relu')

    self.conv_transpose_2 = keras.layers.Conv2DTranspose(filters = 256, kernel_size = 2, strides = 2, padding = 'same')

    self.conv_13 = keras.layers.Conv2D(filters = 256, kernel_size = 3, activation = 'relu')
    self.conv_14 = keras.layers.Conv2D(filters = 256, kernel_size = 3, activation = 'relu')

    self.conv_transpose_3 = keras.layers.Conv2DTranspose(filters = 128, kernel_size = 2, strides = 2, padding = 'same')

    self.conv_15 = keras.layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu')
    self.conv_16 = keras.layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu')

    self.conv_transpose_4 = keras.layers.Conv2DTranspose(filters = 64, kernel_size = 2, strides = 2, padding = 'same')

    self.conv_17 = keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu')
    self.conv_18 = keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu')
    self.conv_19 = keras.layers.Conv2D(filters = 2, kernel_size = 1, activation = 'relu')

    self.flatten = keras.layers.Flatten()
    self.dense_1 = keras.layers.Dense(units = 1024, activation = 'relu')
    self.dense_2 = keras.layers.Dense(units = 1, activation = 'relu')

  def call(self, input):
    out = self.conv_1(input)
    out = self.conv_2(out)
    crop_4 = self.crop_4(out)
    out = self.max_pool_1(out)

    out = self.conv_3(out)
    out = self.conv_4(out)
    crop_3 = self.crop_3(out)
    out = self.max_pool_2(out)

    out = self.conv_5(out)
    out = self.conv_6(out)
    crop_2 = self.crop_2(out)
    out = self.max_pool_3(out)

    out = self.conv_7(out)
    out = self.conv_8(out)
    crop_1 = self.crop_1(out)
    out = self.max_pool_4(out)

    out = self.conv_9(out)
    out = self.conv_10(out)

    out = self.conv_transpose_1(out)
    out = tf.concat([out, crop_1], axis = 3)

    out = self.conv_11(out)
    out = self.conv_12(out)

    out = self.conv_transpose_2(out)                 
    out = tf.concat([out, crop_2], axis = 3)

    out = self.conv_13(out)
    out = self.conv_14(out)

    out = self.conv_transpose_3(out)                 
    out = tf.concat([out, crop_3], axis = 3)

    out = self.conv_15(out)
    out = self.conv_16(out)

    out = self.conv_transpose_4(out)                 
    out = tf.concat([out, crop_4], axis = 3)

    out = self.conv_17(out)
    out = self.conv_18(out)
    out = self.conv_19(out)

    out = self.flatten(out)
    out = self.dense_1(out)
    out = self.dense_2(out)

    return out

  def summary(self):
    x = keras.Input((572, 572, 3))
    return keras.Model(inputs = x, outputs = self.call(x)).summary()

# x_1 = tf.zeros((100, 64, 64, 512))
# x_2 = tf.zeros((100, 28, 28, 1024))
# layer_1 = keras.layers.Cropping2D(cropping = ((4, 4), (4, 4)))
# layer_2 = keras.layers.UpSampling2D(size = (2, 2))
# # layer_2 = keras.layers.Conv2DTranspose(filters = 512, kernel_size = 2, strides = 2, padding = 'same')
# output_1 = layer_1(x_1)
# output_2 = layer_2(x_2)
# output = tf.concat([output_1, output_2], axis = 3)
# tf.shape(output)

unet_model = UNet()

data_augmentation = tf.keras.Sequential([
    keras.layers.RandomFlip("horizontal_and_vertical"),
    keras.layers.RandomRotation(0.2),
])

model = keras.Sequential([
    data_augmentation,
    unet_model
])

model.build((100, 572, 572, 3))
model.summary()

model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'BinaryCrossentropy', metrics = ['accuracy'])
# r = model.fit(train_x, train_y, epochs = 50, batch_size = 32, validation_data = (test_x, test_y))
r = model.fit(train_x[:50], train_y[:50], epochs = 50)

