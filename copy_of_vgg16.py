# -*- coding: utf-8 -*-
"""Copy of vgg16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-E1joBBv4CsMKkBIsFwZ6XNC4AVK_gHY
"""

import os
import keras
import numpy as np
import pandas as pd
import cv2
import tensorflow
from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, ZeroPadding2D
from sklearn.preprocessing import LabelEncoder , OneHotEncoder
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support

from google.colab import drive
drive.mount('/content/drive')

dataset_path = os.listdir('/content/drive/MyDrive/Dataset4')
emotion_types = os.listdir('/content/drive/MyDrive/Dataset4')
print (emotion_types)  #what kinds of emotions are in this dataset

print("Types of emotions found: ", len(dataset_path))

emotions = []

for item in emotion_types:
 # Get all the file names
 all_emotions = os.listdir('/content/drive/MyDrive/Dataset4' + '/' +item)
 #print(all_emotion)

 # Add them to the list
 for emotion in all_emotions:
    emotions.append((item, str('emotions_dataset' + '/' +item) + '/' + emotion))
    print(emotions)

# Build a dataframe        
emotions_df = pd.DataFrame(data=emotions, columns=['game no.', 'image'])
print(emotions_df.head())
print(emotions_df.tail())

# Let's check how many samples for each category are present
print("Total number of emotions in the dataset: ", len(emotions_df))

emotion_count = emotions_df['game no.'].value_counts()

print("emotions in each category: ")
print(emotion_count)

path = '/content/drive/MyDrive/Dataset4'


im_size = 224
images = []
labels = []

for i in emotion_types:
    data_path = path + '/'+str(i)  
    filenames = [i for i in os.listdir(data_path) ]
   
    for f in filenames:
        img = cv2.imread(data_path + '/' + f)
        img = cv2.resize(img, (im_size, im_size))
        images.append(img)
        labels.append(i)

images = np.array(images)

images = images.astype('float32') / 255.0
images.shape

y = emotions_df['game no.'].values
# #print(y[:5])

y_labelencoder = LabelEncoder ()
y = y_labelencoder.fit_transform (y)
y = to_categorical(y, 2)
# print (y.shape)
y[:5]

images, y = shuffle(images,y, random_state=1)

train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.20, random_state=1)

#inpect the shape of the training and testing.
print(train_x.shape)
print(train_y.shape)
print(test_x.shape)
print(test_y.shape)

train_y.shape, test_y.shape

from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

vgg = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)

for layer in vgg.layers:
  layer.trainable = False

x = Flatten()(vgg.output)
# x = Dense(1000, activation = 'relu')(x)
prediction = Dense(2, activation='softmax')(x)

model = keras.Model(inputs=vgg.input, outputs=prediction)

#model.compile(optimizer = "Adam", loss = 'BinaryCrossentropy', metrics = ['accuracy'])
model.compile(optimizer = tensorflow.keras.optimizers.Adam(learning_rate = 0.001), loss = 'BinaryCrossentropy', metrics = ['accuracy'])
r = model.fit(train_x, train_y, epochs = 200, batch_size = 32, validation_data = (test_x, test_y))

#from sklearn.model_selection import cross_val_score
#kfold = KFold(n_splits=10, shuffle=True, random_state=1)
#results = cross_val_score(r, train_x, train_y, cv=kfold, scoring='accuracy')
#print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

#print(y)

#print(prediction)

##precision_recall_fscore_support(y, prediction, average='macro')

# accuracies
fig, ax1 = plt.subplots(nrows=1)
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='test acc')
plt.xlabel('No. of Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()
fig.savefig('plotvgg_acc.png',dpi = 2000)

# loss
fig, ax1 = plt.subplots(nrows=1)
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='test loss')
plt.xlabel('no. of epochs')
plt.ylabel('loss')
plt.legend()
plt.show()
fig.savefig('plotvgg_loss.png',dpi = 2000)

predict_x=model.predict(test_x) 
classes_x=np.argmax(predict_x,axis=1)
classes_y=np.argmax(test_y,axis=1)
print(classes_x)
print(classes_y)

test_y = test_y[:,0]

from sklearn.metrics import precision_score,recall_score,f1_score

precision= precision_score(classes_y,classes_x)
print('precision is %0.3f'%precision)

recall= recall_score(classes_y,classes_x)
print('recall is %0.3f'%recall)

f1= f1_score(classes_y,classes_x)
print('f1 is %0.3f'%f1)

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(classes_y, classes_x)
print(matrix)

