# -*- coding: utf-8 -*-
"""inceptionv3 scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X70vmcLWovA78w0hYRIBeP_8zPBpMynz
"""

import os
import keras
import numpy as np
import pandas as pd
import cv2
import tensorflow
from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, ZeroPadding2D
from sklearn.preprocessing import LabelEncoder , OneHotEncoder
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support

from google.colab import drive
drive.mount('/content/drive')

dataset_path = os.listdir('/content/drive/MyDrive/Dataset4')
emotion_types = os.listdir('/content/drive/MyDrive/Dataset4')
print (emotion_types)  #what kinds of emotions are in this dataset

print("Types of emotions found: ", len(dataset_path))

emotions = []

for item in emotion_types:
 # Get all the file names
 all_emotions = os.listdir('/content/drive/MyDrive/Dataset4' + '/' +item)
 #print(all_emotion)

 # Add them to the list
 for emotion in all_emotions:
    emotions.append((item, str('emotions_dataset' + '/' +item) + '/' + emotion))
    print(emotions)

# Build a dataframe        
emotions_df = pd.DataFrame(data=emotions, columns=['game no.', 'image'])
print(emotions_df.head())
print(emotions_df.tail())

# Let's check how many samples for each category are present
print("Total number of emotions in the dataset: ", len(emotions_df))

emotion_count = emotions_df['game no.'].value_counts()

print("emotions in each category: ")
print(emotion_count)

path = '/content/drive/MyDrive/Dataset4'


im_size = 299
images = []
labels = []

for i in emotion_types:
    data_path = path + '/'+str(i)  
    filenames = [i for i in os.listdir(data_path) ]
   
    for f in filenames:
        img = cv2.imread(data_path + '/' + f)
        img = cv2.resize(img, (im_size, im_size))
        images.append(img)
        labels.append(i)

images = np.array(images)

images = images.astype('float32') / 255.0
images.shape

y = emotions_df['game no.'].values
# #print(y[:5])

y_labelencoder = LabelEncoder ()
y = y_labelencoder.fit_transform (y)
y = to_categorical(y, 2)
# print (y.shape)
y[:5]

images, y = shuffle(images,y, random_state=1)

train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.20, random_state=1)

#inpect the shape of the training and testing.
print(train_x.shape)
print(train_y.shape)
print(test_x.shape)
print(test_y.shape)

train_y.shape, test_y.shape

from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.inception_v3 import InceptionV3
from keras.applications.inception_v3 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
import numpy as np
from glob import glob
import matplotlib.pyplot as plt
#from tensorflow.keras.applications.resnet50 import ResNet50
#from keras_applications.resnet import ResNet50
#from keras.applications.resnet50 import ResNet50

#inception naive version

def inception_module(x, f1, f2, f3):
	# 1x1 conv
	conv1 =  keras.layers.Conv2D(f1, (1,1), padding='same', activation='relu')(x)
	# 3x3 conv
	conv3 = keras.layers.Conv2D(f2, (3,3), padding='same', activation='relu')(x)
	# 5x5 conv
	conv5 = keras.layers.Conv2D(f3, (5,5), padding='same', activation='relu')(x)
	# 3x3 max pooling
	pool = keras.layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)
	# concatenate filters
	out = keras.layers.merge.concatenate([conv1, conv3, conv5, pool])
	return out

img_input = keras.Input(shape=(299, 299, 3))
classes=2
#WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'
#WEIGHTS_PATH = 'inception_v3_weights_tf_dim_ordering_tf_kernels.h5'
#WEIGHTS_PATH = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'
channel_axis=3

def conv2d_bn(x,filters,num_row,num_col,padding='same',strides=(1, 1)):
   
    x = keras.layers.Conv2D(filters, (num_row, num_col),strides=strides,padding=padding)(x)
    x = keras.layers.BatchNormalization(axis=3, scale=False)(x)
    x = keras.layers.Activation('relu')(x)
    return x

def inc_block_a(x):    
    branch1x1 = conv2d_bn(x, 64, 1, 1)  # 64 filters of 1*1

    branch5x5 = conv2d_bn(x, 48, 1, 1)  #48 filters of 1*1
    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)

    branch3x3dbl = conv2d_bn(x, 64, 1, 1)
    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)
    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)

    branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)
    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)
    x = keras.layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool], axis=channel_axis)
    return x

def reduction_block_a(x):  
    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')

    branch3x3dbl = conv2d_bn(x, 64, 1, 1)
    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)
    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')

    branch_pool = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)
    x = keras.layers.concatenate([branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)
    return x

# 17 x 17 x 768
def inc_block_b(x):
    branch1x1 = conv2d_bn(x, 192, 1, 1)

    branch7x7 = conv2d_bn(x, 128, 1, 1)
    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)
    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)

    branch7x7dbl = conv2d_bn(x, 128, 1, 1)
    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)
    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)
    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)
    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)

    branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1),padding='same')(x)
    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)
    x = keras.layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool], axis=channel_axis)
    return x

# mixed 8: 8 x 8 x 1280
def reduction_block_b(x): 
    branch3x3 = conv2d_bn(x, 192, 1, 1)
    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,strides=(2, 2), padding='valid')

    branch7x7x3 = conv2d_bn(x, 192, 1, 1)
    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)
    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)
    branch7x7x3 = conv2d_bn( branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')

    branch_pool = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)
    x = keras.layers.concatenate([branch3x3, branch7x7x3, branch_pool], axis=channel_axis)
    return x

def inc_block_c(x):        
        branch1x1 = conv2d_bn(x, 320, 1, 1)

        branch3x3 = conv2d_bn(x, 384, 1, 1)
        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)
        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)
        branch3x3 = keras.layers.concatenate([branch3x3_1, branch3x3_2],axis=channel_axis)

        branch3x3dbl = conv2d_bn(x, 448, 1, 1)
        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)
        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)
        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)
        branch3x3dbl = keras.layers.concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)

        branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)
        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)
        x = keras.layers.concatenate( [branch1x1, branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)
        return x

img_input = keras.Input(shape=(299, 299, 3))  #shape=(None, 299, 299, 3)

# input image size: 299 x 299 x 3
x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid') # 149 x 149 x 32
x = conv2d_bn(x, 32, 3, 3, padding='valid')  # 147 x 147 x 32
x = conv2d_bn(x, 64, 3, 3) # 147 x 147 x 64

x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)   # 73  x 73 x 64
x = conv2d_bn(x, 80, 1, 1, padding='valid') # 73 x 73 x 80
x = conv2d_bn(x, 192, 3, 3, padding='valid')  # 71 x 71 x 192
x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)  # 35 x 35 x 192


x=inc_block_a(x) #35, 35, 256
x=inc_block_a(x) #35, 35, 256
x=inc_block_a(x) #35, 35, 256

x=reduction_block_a(x) #17, 17, 736

x=inc_block_b(x) #17, 17, 768
x=inc_block_b(x) #17, 17, 768
x=inc_block_b(x) #17, 17, 768
x=inc_block_b(x) #17, 17, 768

x=reduction_block_b(x) #shape=(None, 8, 8, 1280)

x=inc_block_c(x) # shape=(None, 8, 8, 2048) 
x=inc_block_c(x) # shape=(None, 8, 8, 2048) 

x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x) # shape=(None, 2048)

x = keras.layers.Dense(classes, activation='softmax', name='predictions')(x) #shape=(None, 1000) 



# Create model.
inputs = img_input
model =  keras.Model(inputs, x, name='inception_v3')
model.summary()

#model.compile(optimizer = "Adam", loss = 'BinaryCrossentropy', metrics = ['accuracy'])
model.compile(optimizer = tensorflow.keras.optimizers.Adam(learning_rate = 0.001), loss = 'BinaryCrossentropy', metrics = ['accuracy'])
r = model.fit(train_x, train_y, epochs = 100, batch_size = 32, validation_data = (test_x, test_y))

# accuracies
#plt.ylim(0,1.3)
fig, ax1 = plt.subplots(nrows=1)
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='test acc')
plt.xlabel('No. of Epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()
fig.savefig('plotinceptionacc.png',dpi = 2000)

# loss
fig, ax1 = plt.subplots(nrows=1)
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='test loss')
plt.xlabel('no. of epochs')
plt.ylabel('loss')
plt.legend()
plt.show()
fig.savefig('plotinceptionloss.png',dpi = 2000)

predict_x=model.predict(test_x) 
classes_x=np.argmax(predict_x,axis=1)
classes_y=np.argmax(test_y,axis=1)
print(classes_x)
print(classes_y)

test_y = test_y[:,0]

from sklearn.metrics import precision_score,recall_score,f1_score

precision= precision_score(classes_y,classes_x)
print('precision is %0.3f'%precision)

recall= recall_score(classes_y,classes_x)
print('recall is %0.3f'%recall)

f1= f1_score(classes_y,classes_x)
print('f1 is %0.3f'%f1)

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(classes_y, classes_x)
print(matrix)

